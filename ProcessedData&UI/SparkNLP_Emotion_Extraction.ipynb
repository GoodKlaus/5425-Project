{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Emotion_Extraction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyORnLh3OFSJS0zGzQcHEjZT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cwMhq_5Vd9UG"},"outputs":[],"source":["# Install PySpark and Spark NLP\n","! pip install -q pyspark==3.1.2 spark-nlp"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import json\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","import sparknlp\n","from sparknlp.pretrained import PretrainedPipeline\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import *\n","from sparknlp.annotator import *\n","from sparknlp.base import *"],"metadata":{"id":"IRJPQdrueBiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark = sparknlp.start()"],"metadata":{"id":"UhRsZxZBeL8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('processed_data_Ukraine.csv')"],"metadata":{"id":"1meRrwPJeGBn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[['content']]\n","df['content'] = df['content'].astype(str)\n","df = df[df['content'].str.split().str.len().lt(30) & df['content'].str.split().str.len().gt(6)]\n","df.reset_index(inplace=True)\n","df.head()"],"metadata":{"id":"UEE2mKn0eH-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","sparkdf = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n","data = sparkdf.createDataFrame(df)"],"metadata":{"id":"JKP9lK_deO5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n","    .setInputCol(\"content\")\\\n","    .setOutputCol(\"document\")\n","    \n","use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n"," .setInputCols([\"document\"])\\\n"," .setOutputCol(\"sentence_embeddings\")\n","\n","\n","sentimentdl = ClassifierDLModel.pretrained(name='classifierdl_use_emotion')\\\n","    .setInputCols([\"sentence_embeddings\"])\\\n","    .setOutputCol(\"sentiment\")\n","\n","nlpPipeline = Pipeline(\n","      stages = [\n","          documentAssembler,\n","          use,\n","          sentimentdl\n","      ])"],"metadata":{"id":"47M2obQteTT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emo_labels = { emo:(i+1) for i, emo in enumerate(\"surprise joy sadness fear\".split())}\n","\n","def emotion_processing(data, pipeline):\n","  processed_tweets = pipeline.fit(data.select('content')).transform(data.select('content'))\n","  text = list((((processed_tweets.select(F.explode(F.arrays_zip('document.result')).alias(\"col\")).select(F.expr(\"col\").alias(\"text\"))).toPandas())).text)\n","  text = [text[0] for text in text] # extract raw text\n","  score = list((((processed_tweets.select(F.explode(F.arrays_zip('sentiment.result')).alias(\"col1\")).select(F.expr(\"col1\").alias(\"sentiment\"))).toPandas())).sentiment)\n","  \n","  df1 = pd.DataFrame(list(zip(text,score)), columns = ['content','sentiment'])\n","  df1['emotion'] = df1['sentiment'].apply(lambda x: x[0])\n","  df1['label'] = df1['emotion'].apply(lambda x: emo_labels[x])\n","  \n","  df1.drop(['sentiment'], axis=1, inplace=True)\n","  return df1\n","\n"],"metadata":{"id":"gSN-6oRgeVtP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_new = emotion_processing(data, nlpPipeline)"],"metadata":{"id":"8UwkmfwGeXfv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_new.to_csv('sparknlp_Ukraine.csv')"],"metadata":{"id":"vGAykiX1eap3"},"execution_count":null,"outputs":[]}]}